{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML - Project - Phase 1\n",
    "====\n",
    "- Ahmed Soliman - 201802284\n",
    "- Abhygian Kishor - 201909552\n",
    "- Mohammed Arif - 201908981"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#- Introduction\n",
    "======="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "Customers cancel hotel reservations (or simply don't show up) due to a variety of reasons such as scheduling conflicts, change of plans, etc. Knowing if a customer will honor a reservation is hard and with the advent of online reservations for hotels, prediciting this behaivour has become an even more difficult task. Reservation cancellation leads to unfilled rooms which means hotels lose out on revenue.\n",
    "\n",
    "Analysing the resevation cancellation dataset is crucial step in understanding and making sense of the large amount of data to efficiently predict reservation cancellations. Predicting this customer behaviour will provide hotels several benefits such as better revenue optimization, increased customer staisfaction, and accurate forecasting of demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives\n",
    "====\n",
    "1 - By producing insightful summary statistics and visualization we aim to uncover patterns and insights on some of the reasons why customers may cancel.\n",
    "\n",
    "2 - We also aim to investigate relations in different attributes of the dataset to gain a deeper understanding of the data.\n",
    "\n",
    "3 - We aim to set expectations for future improvements and developments in understanding customer behaviour through establishing a baseline performance by training intial models such as Decision Trees, Random Forest, K-Nearest Neighbours and Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset \n",
    "====\n",
    "### Link : https://www.kaggle.com/competitions/playground-series-s3e7/overview\n",
    "The dataset contains the different attributes of customers' reservation details. The detailed data dictionary is given below:\n",
    "* Booking_ID: unique identifier of each booking\n",
    "* No of adults: Number of adults\n",
    "* No of children: Number of Children\n",
    "* noofweekend_nights: Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel\n",
    "* noofweek_nights: Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n",
    "* typeofmeal_plan: Type of meal plan booked by the customer:\n",
    "* requiredcarparking_space: Does the customer require a car parking space? (0 - No, 1- Yes)\n",
    "* roomtypereserved: Type of room reserved by the customer. The values are ciphered (encoded) by INN Hotels.\n",
    "* lead_time: Number of days between the date of booking and the arrival date\n",
    "* arrival_year: Year of arrival date\n",
    "* arrival_month: Month of arrival date\n",
    "* arrival_date: Date of the month\n",
    "* Market segment type: Market segment designation.\n",
    "* repeated_guest: Is the customer a repeated guest? (0 - No, 1- Yes)\n",
    "* noofprevious_cancellations: Number of previous bookings that were canceled by the customer prior to the current booking\n",
    "* noofpreviousbookingsnot_canceled: Number of previous bookings not canceled by the customer prior to the current booking\n",
    "* avgpriceper_room: Average price per day of the reservation; prices of the rooms are dynamic. (in euros)\n",
    "* noofspecial_requests: Total number of special requests made by the customer (e.g. high floor, view from the room, etc)\n",
    "* booking_status: Flag indicating if the booking was canceled or not. (0 - Cancelled, 1 - Not Cancelled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#- Implementations\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting training dataset from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./playground-series-s3e7/train.csv').drop(columns='id')\n",
    "test = pd.read_csv('./playground-series-s3e7/test.csv').drop(columns='id')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data statistics\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Python statistics Module: Mathematical statistics functions in Python\n",
    "from statistics import *\n",
    "import pandas as pd\n",
    "data = train['booking_status']\n",
    "# print(sorted(data))\n",
    "print(\"Min\", data.min())\n",
    "print(\"Max\", data.max())\n",
    "print(\"mean\",mean(data))\n",
    "print(\"median\",median(data)) \n",
    "print(\"mode\",mode(data)) #Single mode (most common value) of discrete or nominal data.\n",
    "print(\"multimode\",multimode(data)) #List of modes (most common values) of discrete or nominal data.\n",
    "print(\"quantiles\",quantiles(data)) #Divide data into intervals with equal probability\n",
    "print(\"variance\",variance(data)) #sample variance of data\n",
    "print(\"std\",stdev(data))  #sample standard deviation\n",
    "print(\"Value counts: \\n\", data.value_counts())\n",
    "\n",
    "\n",
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting non-continuous attributes with booking status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "non_continuous = ['no_of_special_requests','type_of_meal_plan', 'required_car_parking_space', 'room_type_reserved',\n",
    "               'market_segment_type', 'repeated_guest', 'no_of_previous_bookings_not_canceled', 'no_of_previous_cancellations' ] \n",
    "\n",
    "\n",
    "\n",
    "nrows = int(np.ceil(len(non_continuous)/4))\n",
    "\n",
    "# create the subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=4, figsize=(20, nrows*4))\n",
    "\n",
    "for i, attr in enumerate(non_continuous):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax=axes[row,col]\n",
    "    cross_tab = pd.crosstab(train[attr], train['booking_status'])\n",
    "    if(attr == 'no_of_previous_bookings_not_canceled' or attr == 'no_of_previous_cancellations'):\n",
    "            #These attributes have too many non zero values, generalising into '0' and '1 or more'\n",
    "            cross_tab = pd.crosstab(train[attr].apply(lambda x: '0' if x == 0 else '1+'), train['booking_status'])\n",
    "    cross_tab.plot(kind='bar', ax=ax, color='gr')\n",
    "    ax.set_xlabel(attr)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.legend([\"Not Cancelled\", \"Cancelled\"])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above graphs we can see the following relationships:**\n",
    "\n",
    "* People who made special requests (maybe a good view, or special decorations) did not cancel as much as people who did not make any requests. We can see that as the number of  requests goes up the ratio of cancellations goes down significantly.\n",
    "\n",
    "* Repeated guests also had very low cancellations compared to first time guests. As the number of previous bookings not cancelled and the number of previous cancellations are only possible for repeated guests, these attributes are also inversely proportional to the booking status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualization - seaborn\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- boxplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "non_cont = non_continuous.copy()\n",
    "non_cont.append('booking_status')\n",
    "df_continuous = train.copy().drop(columns=non_cont, axis=1)\n",
    "df_continuous.describe()\n",
    "# calculate the number of rows based on the number of columns and 3 plots per row\n",
    "nrows = int(np.ceil(len(df_continuous.columns)/3))\n",
    "\n",
    "# create the subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=3, figsize=(20, nrows*4))\n",
    "\n",
    "# plot the boxplots\n",
    "for i, column in enumerate(df_continuous.columns):\n",
    "    row = i // 3\n",
    "    col = i % 3\n",
    "    sns.boxplot(data=df_continuous, x=column, ax=axes[row, col])\n",
    "    axes[row, col].set_title(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- histograms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of rows based on the number of columns and 3 plots per row\n",
    "df_non_continuous = train.copy()[non_continuous]\n",
    "nrows = int(np.ceil(len(df_non_continuous.columns)/4))\n",
    "# create the subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=4, figsize=(20, nrows*4))\n",
    "\n",
    "# plot the boxplots\n",
    "for i, column in enumerate(df_non_continuous.columns):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    sns.histplot(data=df_non_continuous, x=column, ax=axes[row, col])\n",
    "    axes[row, col].set_title(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We split the original dataset into two categories, continuous and non-continuous, to visualize the data using box plots for continuous variables and histogram plots for non-continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy = train.copy()\n",
    "print(train_copy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dups = train_copy.drop(columns = 'booking_status').duplicated().sum()\n",
    "\n",
    "print(f'Number of duplicates in training dataset: {train_dups}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy = train_copy.drop_duplicates(subset = train.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_copy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the anomalies we noticed:\n",
    "1. Anomalous dates, such as 29th February\n",
    "2. Average price per room = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing entries where average price of room is 0. This is not possible.\n",
    "train_copy = train_copy.loc[train_copy['avg_price_per_room'] != 0]\n",
    "train_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing anomolous dates\n",
    "train_copy.rename(columns = {'arrival_year': 'year', 'arrival_month': 'month', 'arrival_date': 'day'}, inplace = True)\n",
    "train_copy['true_date'] = pd.to_datetime(train_copy[['year', 'month', 'day']], errors = 'coerce')\n",
    "train_copy = train_copy.dropna()\n",
    "train_copy = train_copy.drop(columns = 'true_date')\n",
    "train_copy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_copy.corr()\n",
    "fig, axes = plt.subplots(figsize=(30, 10))\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(corr, mask=mask, linewidths=.5, cmap='YlOrBr_r', annot=True)\n",
    "plt.title('Train Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the heatmap above, we infer the following:**\n",
    "1. Booking status is most correlated to lead time, i.e. The further ahead in time the room is booked, the more likely it is to be cancelled\n",
    "2. Number of children is closely related to room type reserved as more children would mean larger rooms\n",
    "3. Consequently, the average price per room is also correlated to number of children as larger rooms would have higher price\n",
    "4. Unsurprisingly, the room type reservered is related to average price per room\n",
    "5. If guest is a repeat guest, then naturally the number of previous bookings not cancelled will be high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_copy.copy()\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = train.iloc[:,:-1]\n",
    "y_original = train.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original, y_original, test_size=0.2, random_state=42)\n",
    "print(\"Shapes:\")\n",
    "print(\" X_train: \",X_train.shape)\n",
    "print(\" X_test: \",X_test.shape)\n",
    "print(\" y_train: \",y_train.shape)\n",
    "print(\" y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "print(\"Training Accuracy:\", tree_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decsion tree predictions on X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_clf.predict(X_test)\n",
    "print(\"Predicted Labels:\", y_pred[:30])\n",
    "print(\"True Labels:     \", y_test.to_numpy()[:30])\n",
    "print(\"Testing Accuracy:\", metrics.accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix for Decision tree classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred) \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=tree_clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree_clf, X_train, y_train, cv=50)\n",
    "print(scores)\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using GridSearchCV to find hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10, 20, 40],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                              params,\n",
    "                              cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search_cv.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "tree_clf = grid_search_cv.best_estimator_\n",
    "print(\"Criterion:         \", tree_clf.criterion)\n",
    "print(\"Min Samples Leaf:  \", tree_clf.min_samples_leaf)\n",
    "print(\"Depth:             \", tree_clf.max_depth)\n",
    "print(\"Min Samples Split: \", tree_clf.min_samples_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plot_tree(tree_clf, filled=True)\n",
    "plt.title(\"Decision tree trained on all attributes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest_clf = RandomForestClassifier(n_estimators=200, random_state=42,max_samples=5000)\n",
    "randomForest_clf.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",randomForest_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=20)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred= model.predict(X_test)\n",
    "print(\"Testing Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X_train, y_train, cv=50)\n",
    "print(scores)\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "lin_reg = LogisticRegression(max_iter=1000)\n",
    "lin_reg.fit(X_scaled, y_train)\n",
    "print(lin_reg.intercept_)\n",
    "print(lin_reg.coef_)\n",
    "y_pred= lin_reg.predict(X_test)\n",
    "print(\"Testing Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Testing Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Testing Recall:\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"Testing f1 Score:\", metrics.f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "====\n",
    "In conclusion, our data analysis for the hotel reservation cancellation dataset has been successful. Using the summary statistics and visualization has helped us to uncover patterns and relationships in the data such as the correlation between the number of special requests and the booking status. Another interesting relationship was that of lead time and booking status. We also noticed some anomalies such as rows that had the same attributes but different class labels and removed them to better clean our data. Investigating these relationships has provided us with a better understanding of customer behaviour and what factors influence it. By training initial models we have also established a solid foundation upon which we can have future developments and improvements."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
