{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ML - Project - Phase 1\n",
    "====\n",
    "- Ahmed Soliman 201802284\n",
    "- Abhygian Kishor\n",
    "- Mohammed Arif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#- Introduction\n",
    "======="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "Customers cancel hotel reservations (or simply don't show up) due to a variety of reasons such as scheduling conflicts, change of plans, etc. Knowing if a customer will honor a reservation is hard and with the advent of online reservations for hotels, prediciting this behaivour has become an even more difficult task. Reservation cancellation leads to unfilled rooms which means hotels lose out on revenue.\n",
    "\n",
    "Analysing the resevation cancellation dataset is crucial step in understanding and making sense of the large amount of data to efficiently predict reservation cancellations. Predicting this customer behaviour will provide hotels several benefits such as better revenue optimization, increased customer staisfaction, and accurate forecasting of demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives\n",
    "====\n",
    "1 - By producing insightful summary statistics and visualization we aim to uncover patterns and insights on some of the reasons why customers may cancel.\n",
    "\n",
    "2 - We also aim to investigate relations in different attributes of the dataset to gain a deeper understanding of the data.\n",
    "\n",
    "3 - We aim to set expectations for future improvements and developments in understanding customer behaviour through establishing a baseline performance by training intial models such as Decision Trees, Random Forest, K-Nearest Neighbours and Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#- Implementations\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./playground-series-s3e7/train.csv').drop(columns='id')\n",
    "test = pd.read_csv('./playground-series-s3e7/test.csv').drop(columns='id')\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahmed\n",
    "====\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data statistics\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Python statistics Module: Mathematical statistics functions in Python\n",
    "from statistics import *\n",
    "import pandas as pd\n",
    "data = train['booking_status']\n",
    "# print(sorted(data))\n",
    "print(\"Min\", data.min())\n",
    "print(\"Max\", data.max())\n",
    "print(\"mean\",mean(data))\n",
    "print(\"median\",median(data)) \n",
    "print(\"mode\",mode(data)) #Single mode (most common value) of discrete or nominal data.\n",
    "print(\"multimode\",multimode(data)) #List of modes (most common values) of discrete or nominal data.\n",
    "print(\"quantiles\",quantiles(data)) #Divide data into intervals with equal probability\n",
    "print(\"variance\",variance(data)) #sample variance of data\n",
    "print(\"std\",stdev(data))  #sample standard deviation\n",
    "\n",
    "\n",
    "train.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualization - matplotlib\n",
    "====\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- boxplots\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of rows based on the number of columns and 3 plots per row\n",
    "nrows = int(np.ceil(len(train.columns)/4))\n",
    "\n",
    "# create the subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=4, figsize=(20, nrows*4))\n",
    "\n",
    "# plot the boxplots\n",
    "for i, column in enumerate(train.columns):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    axes[row, col].boxplot(train[column])\n",
    "    axes[row, col].set_title(column)\n",
    "# plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- histograms\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histogram\n",
    "train.hist(bins=50, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- stem\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=nrows, ncols=4, figsize=(20, nrows*4))\n",
    "for i, column in enumerate(train.columns):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    axes[row, col].stem(train[column])\n",
    "#     axes[row, col].margins(0.05)\n",
    "    axes[row, col].set_title(column)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data visualization - seaborn\n",
    "===="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- boxplots\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "\n",
    "# calculate the number of rows based on the number of columns and 3 plots per row\n",
    "nrows = int(np.ceil(len(train.columns)/4))\n",
    "\n",
    "# create the subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=4, figsize=(20, nrows*4))\n",
    "\n",
    "# plot the boxplots\n",
    "for i, column in enumerate(train.columns):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    sns.boxplot(data=train, x=column, ax=axes[row, col])\n",
    "    axes[row, col].set_title(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- histograms\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histogram\n",
    "# train.hist(bins=50, figsize=(20, 15))\n",
    "\n",
    "# plot histograms for each column separately\n",
    "\n",
    "# calculate the number of rows based on the number of columns and 3 plots per row\n",
    "nrows = int(np.ceil(len(train.columns)/4))\n",
    "\n",
    "# create the subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=4, figsize=(20, nrows*4))\n",
    "\n",
    "# plot the boxplots\n",
    "for i, column in enumerate(train.columns):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    sns.histplot(data=train, x=column, ax=axes[row, col])\n",
    "    axes[row, col].set_title(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- stem\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the number of rows based on the number of columns and 3 plots per row\n",
    "nrows = int(np.ceil(len(train.columns)/4))\n",
    "\n",
    "# create the subplots\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=4, figsize=(20, nrows*4))\n",
    "\n",
    "# plot the line plots\n",
    "for i, column in enumerate(train.columns):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    sns.lineplot(data=train, x=train.index, y=column, ax=axes[row, col])\n",
    "    axes[row, col].set_title(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kishor\n",
    "====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print('I am doing work!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a new cell for abhigyan\n",
    "# somthing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Arif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = train.iloc[:,:-1]\n",
    "y_original = train.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_original, y_original, test_size=0.2, random_state=42)\n",
    "print(\"Shapes:\")\n",
    "print(\" X_train: \",X_train.shape)\n",
    "print(\" X_test: \",X_test.shape)\n",
    "print(\" y_train: \",y_train.shape)\n",
    "print(\" y_test: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "print(\"Training Accuracy:\", tree_clf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,8))\n",
    "#plot_tree(tree_clf, filled=True)\n",
    "#plt.title(\"Decision tree trained on all attributes\")\n",
    "#plt.show()\n",
    "\n",
    "#Takes too long "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decsion tree predictions on X_test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_clf.predict(X_test)\n",
    "print(\"Predicted Labels:\", y_pred[:30])\n",
    "print(\"True Labels:     \", y_test.to_numpy()[:30])\n",
    "print(\"Testing Accuracy:\", metrics.accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix for Decision tree classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test, y_pred) \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=matrix, display_labels=tree_clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(tree_clf, X_train, y_train, cv=50)\n",
    "print(scores)\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using GridSearchCV to find hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10, 20, 40],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "}\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                              params,\n",
    "                              cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search_cv.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "tree_clf = grid_search_cv.best_estimator_\n",
    "print(\"Criterion:         \", tree_clf.criterion)\n",
    "print(\"Min Samples Leaf:  \", tree_clf.min_samples_leaf)\n",
    "print(\"Depth:             \", tree_clf.max_depth)\n",
    "print(\"Min Samples Split: \", tree_clf.min_samples_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plot_tree(tree_clf, filled=True)\n",
    "plt.title(\"Decision tree trained on all attributes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest_clf = RandomForestClassifier(n_estimators=200, random_state=42,max_samples=5000)\n",
    "randomForest_clf.fit(X_train, y_train)\n",
    "print(\"Accuracy:\",randomForest_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=20)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred= model.predict(X_test)\n",
    "print(\"Testing Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X_train, y_train, cv=50)\n",
    "print(scores)\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "lin_reg = LogisticRegression(max_iter=1000)\n",
    "lin_reg.fit(X_scaled, y_train)\n",
    "print(lin_reg.intercept_)\n",
    "print(lin_reg.coef_)\n",
    "y_pred= lin_reg.predict(X_test)\n",
    "print(\"Testing Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"Testing Precision:\", metrics.precision_score(y_test, y_pred))\n",
    "print(\"Testing Recall:\", metrics.recall_score(y_test, y_pred))\n",
    "print(\"Testing f1 Score:\", metrics.f1_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "====\n",
    "\n",
    "In conclusion, our data analysis project has been successful in achieving its objectives. We have produced insightful summary statistics and visualizations that have helped us to uncover patterns and insights in the data. Through the removal of outliers and handling of missing values and duplicates, we have developed a cleaner and more accurate dataset that can be used for further analysis. Investigation of relationships between different attributes has provided us with a deeper understanding of the data and the factors that influence it. We have identified correlations between attributes that can be used to make predictions and inform decision-making processes. Finally, by establishing a baseline performance through initial model training, we have set expectations for future improvements and developments in the data analysis process. Our analysis has provided us with valuable insights that can be used to make informed decisions and improve business processes. Overall, we are confident that our data analysis project has been a success and has provided a solid foundation for future analysis and improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
